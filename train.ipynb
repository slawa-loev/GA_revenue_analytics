{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2efe7bcb-dcfb-4856-ba40-cf43575f07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # disabling scientific notation in pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b614c1e6-3cc5-432c-8f88-24ef87a9ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train.csv\", index_col=0) \n",
    "y_train = pd.read_csv(\"data/y_train.csv\", index_col=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90203859-7eed-4be2-abb1-3c65191da7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cat = ['visitNumber', 'totals_bounces', 'totals_hits', 'totals_newVisits', 'totals_pageviews', 'device_isMobile', 'date_dow', 'date_hours', 'date_dom', 'month', 'days_since_visit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b7c4c8-12ca-4b39-9cca-f02d0b8bd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [c for c in X_train.columns if c not in non_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd46d76a-1a5f-4ffa-972b-05ab5e0283b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channelGrouping', 'visitNumber', 'totals_bounces', 'totals_hits',\n",
       "       'totals_newVisits', 'totals_pageviews', 'device_browser',\n",
       "       'device_deviceCategory', 'device_isMobile', 'device_operatingSystem',\n",
       "       'geoNetwork_city', 'geoNetwork_continent', 'geoNetwork_country',\n",
       "       'geoNetwork_metro', 'geoNetwork_networkDomain', 'geoNetwork_region',\n",
       "       'geoNetwork_subContinent', 'trafficSource_adContent',\n",
       "       'trafficSource_adwordsClickInfo.adNetworkType',\n",
       "       'trafficSource_adwordsClickInfo.page',\n",
       "       'trafficSource_adwordsClickInfo.slot', 'trafficSource_campaign',\n",
       "       'trafficSource_isTrueDirect', 'trafficSource_keyword',\n",
       "       'trafficSource_medium', 'trafficSource_referralPath',\n",
       "       'trafficSource_source', 'date_dow', 'date_hours', 'date_dom', 'month',\n",
       "       'days_since_visit', 'source_country', 'campaign_medium',\n",
       "       'browser_category', 'browser_os',\n",
       "       'device_deviceCategory_channelGrouping', 'channelGrouping_browser',\n",
       "       'channelGrouping_OS', 'geoNetwork_city_device_browser',\n",
       "       'geoNetwork_city_device_deviceCategory',\n",
       "       'geoNetwork_city_device_operatingSystem',\n",
       "       'geoNetwork_city_trafficSource_source',\n",
       "       'geoNetwork_continent_device_browser',\n",
       "       'geoNetwork_continent_device_deviceCategory',\n",
       "       'geoNetwork_continent_device_operatingSystem',\n",
       "       'geoNetwork_continent_trafficSource_source',\n",
       "       'geoNetwork_country_device_browser',\n",
       "       'geoNetwork_country_device_deviceCategory',\n",
       "       'geoNetwork_country_device_operatingSystem',\n",
       "       'geoNetwork_country_trafficSource_source',\n",
       "       'geoNetwork_metro_device_browser',\n",
       "       'geoNetwork_metro_device_deviceCategory',\n",
       "       'geoNetwork_metro_device_operatingSystem',\n",
       "       'geoNetwork_metro_trafficSource_source',\n",
       "       'geoNetwork_networkDomain_device_browser',\n",
       "       'geoNetwork_networkDomain_device_deviceCategory',\n",
       "       'geoNetwork_networkDomain_device_operatingSystem',\n",
       "       'geoNetwork_networkDomain_trafficSource_source',\n",
       "       'geoNetwork_region_device_browser',\n",
       "       'geoNetwork_region_device_deviceCategory',\n",
       "       'geoNetwork_region_device_operatingSystem',\n",
       "       'geoNetwork_region_trafficSource_source',\n",
       "       'geoNetwork_subContinent_device_browser',\n",
       "       'geoNetwork_subContinent_device_deviceCategory',\n",
       "       'geoNetwork_subContinent_device_operatingSystem',\n",
       "       'geoNetwork_subContinent_trafficSource_source', 'content_source',\n",
       "       'medium_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9a4c9c55-cce7-47e1-a480-4867b62c5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, accuracy_score#, recall_score, roc_auc_score, pr\n",
    "\n",
    "def lgb_f2_score(y_true, y_pred):\n",
    "    \n",
    "    y_pred = np.round(y_pred) # scikits fbeta doesn't like probabilities as they are continuous\n",
    "    #print(y_true)\n",
    "    #print(y_pred)\n",
    "    return 'f2', fbeta_score(y_true, y_pred, beta=2), True #https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "632cbf31-2f76-482c-bc53-cc165323c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, eval_x, train_y, eval_y = train_test_split(X_train, y_train, test_size=0.1)\n",
    "\n",
    "clf = lgb.LGBMClassifier(objective=\"binary\", n_estimators=1000)\n",
    "eval_set = [(eval_x, eval_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0449183-2b97-408e-bcca-7a7fbff041b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.0456339\tvalid_0's f2: 0.0786211\n",
      "[2]\tvalid_0's binary_logloss: 0.0431875\tvalid_0's f2: 0.0786211\n",
      "[3]\tvalid_0's binary_logloss: 0.0413935\tvalid_0's f2: 0.0785973\n",
      "[4]\tvalid_0's binary_logloss: 0.0399604\tvalid_0's f2: 0.081448\n",
      "[5]\tvalid_0's binary_logloss: 0.0386895\tvalid_0's f2: 0.0945662\n",
      "[6]\tvalid_0's binary_logloss: 0.0376287\tvalid_0's f2: 0.11742\n",
      "[7]\tvalid_0's binary_logloss: 0.036702\tvalid_0's f2: 0.130101\n",
      "[8]\tvalid_0's binary_logloss: 0.0358969\tvalid_0's f2: 0.13852\n",
      "[9]\tvalid_0's binary_logloss: 0.0352182\tvalid_0's f2: 0.149341\n",
      "[10]\tvalid_0's binary_logloss: 0.0346191\tvalid_0's f2: 0.175464\n",
      "[11]\tvalid_0's binary_logloss: 0.0340844\tvalid_0's f2: 0.181766\n",
      "[12]\tvalid_0's binary_logloss: 0.0335962\tvalid_0's f2: 0.187158\n",
      "[13]\tvalid_0's binary_logloss: 0.0331782\tvalid_0's f2: 0.192253\n",
      "[14]\tvalid_0's binary_logloss: 0.0327448\tvalid_0's f2: 0.196219\n",
      "[15]\tvalid_0's binary_logloss: 0.0323933\tvalid_0's f2: 0.197425\n",
      "[16]\tvalid_0's binary_logloss: 0.0320787\tvalid_0's f2: 0.210886\n",
      "[17]\tvalid_0's binary_logloss: 0.0317774\tvalid_0's f2: 0.212311\n",
      "[18]\tvalid_0's binary_logloss: 0.0315403\tvalid_0's f2: 0.217639\n",
      "[19]\tvalid_0's binary_logloss: 0.0313049\tvalid_0's f2: 0.220108\n",
      "[20]\tvalid_0's binary_logloss: 0.0310686\tvalid_0's f2: 0.221214\n",
      "[21]\tvalid_0's binary_logloss: 0.0308829\tvalid_0's f2: 0.225468\n",
      "[22]\tvalid_0's binary_logloss: 0.03067\tvalid_0's f2: 0.232032\n",
      "[23]\tvalid_0's binary_logloss: 0.0304915\tvalid_0's f2: 0.234596\n",
      "[24]\tvalid_0's binary_logloss: 0.0303101\tvalid_0's f2: 0.235809\n",
      "[25]\tvalid_0's binary_logloss: 0.0301677\tvalid_0's f2: 0.237355\n",
      "[26]\tvalid_0's binary_logloss: 0.0300417\tvalid_0's f2: 0.239977\n",
      "[27]\tvalid_0's binary_logloss: 0.0299318\tvalid_0's f2: 0.239977\n",
      "[28]\tvalid_0's binary_logloss: 0.0297958\tvalid_0's f2: 0.240113\n",
      "[29]\tvalid_0's binary_logloss: 0.0297147\tvalid_0's f2: 0.245624\n",
      "[30]\tvalid_0's binary_logloss: 0.0296482\tvalid_0's f2: 0.242801\n",
      "[31]\tvalid_0's binary_logloss: 0.0295686\tvalid_0's f2: 0.249366\n",
      "[32]\tvalid_0's binary_logloss: 0.0295835\tvalid_0's f2: 0.249085\n",
      "[33]\tvalid_0's binary_logloss: 0.0294973\tvalid_0's f2: 0.250281\n",
      "[34]\tvalid_0's binary_logloss: 0.029418\tvalid_0's f2: 0.252951\n",
      "[35]\tvalid_0's binary_logloss: 0.0293723\tvalid_0's f2: 0.254499\n",
      "[36]\tvalid_0's binary_logloss: 0.0293238\tvalid_0's f2: 0.254428\n",
      "[37]\tvalid_0's binary_logloss: 0.0292852\tvalid_0's f2: 0.25695\n",
      "[38]\tvalid_0's binary_logloss: 0.0292504\tvalid_0's f2: 0.257022\n",
      "[39]\tvalid_0's binary_logloss: 0.0306858\tvalid_0's f2: 0.255658\n",
      "[40]\tvalid_0's binary_logloss: 0.0299864\tvalid_0's f2: 0.255944\n",
      "[41]\tvalid_0's binary_logloss: 0.029893\tvalid_0's f2: 0.256016\n",
      "[42]\tvalid_0's binary_logloss: 0.0297801\tvalid_0's f2: 0.257343\n",
      "[43]\tvalid_0's binary_logloss: 0.0295585\tvalid_0's f2: 0.258669\n",
      "[44]\tvalid_0's binary_logloss: 0.0295073\tvalid_0's f2: 0.258814\n",
      "[45]\tvalid_0's binary_logloss: 0.0294765\tvalid_0's f2: 0.260723\n",
      "[46]\tvalid_0's binary_logloss: 0.0294366\tvalid_0's f2: 0.25792\n",
      "[47]\tvalid_0's binary_logloss: 0.0329847\tvalid_0's f2: 0.256911\n",
      "[48]\tvalid_0's binary_logloss: 0.0306385\tvalid_0's f2: 0.257559\n",
      "[49]\tvalid_0's binary_logloss: 0.0303955\tvalid_0's f2: 0.257559\n",
      "[50]\tvalid_0's binary_logloss: 0.0382092\tvalid_0's f2: 0.256482\n",
      "[51]\tvalid_0's binary_logloss: 0.0330537\tvalid_0's f2: 0.257199\n",
      "[52]\tvalid_0's binary_logloss: 0.0318115\tvalid_0's f2: 0.257415\n",
      "[53]\tvalid_0's binary_logloss: 0.0306757\tvalid_0's f2: 0.258886\n",
      "[54]\tvalid_0's binary_logloss: 0.0344806\tvalid_0's f2: 0.259631\n",
      "[55]\tvalid_0's binary_logloss: 0.036105\tvalid_0's f2: 0.259414\n",
      "[56]\tvalid_0's binary_logloss: 0.0335927\tvalid_0's f2: 0.259631\n",
      "[57]\tvalid_0's binary_logloss: 0.0364615\tvalid_0's f2: 0.259487\n",
      "[58]\tvalid_0's binary_logloss: 0.0315342\tvalid_0's f2: 0.26014\n",
      "[59]\tvalid_0's binary_logloss: 0.0386785\tvalid_0's f2: 0.259125\n",
      "[60]\tvalid_0's binary_logloss: 0.033752\tvalid_0's f2: 0.259849\n",
      "[61]\tvalid_0's binary_logloss: 0.0370191\tvalid_0's f2: 0.259414\n",
      "[62]\tvalid_0's binary_logloss: 0.0337266\tvalid_0's f2: 0.259849\n",
      "[63]\tvalid_0's binary_logloss: 0.0346175\tvalid_0's f2: 0.258597\n",
      "[64]\tvalid_0's binary_logloss: 0.0412511\tvalid_0's f2: 0.257804\n",
      "[65]\tvalid_0's binary_logloss: 0.0358365\tvalid_0's f2: 0.258524\n",
      "[66]\tvalid_0's binary_logloss: 0.0413675\tvalid_0's f2: 0.257732\n",
      "[67]\tvalid_0's binary_logloss: 0.0533827\tvalid_0's f2: 0.256162\n",
      "[68]\tvalid_0's binary_logloss: 0.0435361\tvalid_0's f2: 0.257445\n",
      "[69]\tvalid_0's binary_logloss: 0.0457589\tvalid_0's f2: 0.257159\n",
      "[70]\tvalid_0's binary_logloss: 0.0440104\tvalid_0's f2: 0.257373\n",
      "[71]\tvalid_0's binary_logloss: 0.0454157\tvalid_0's f2: 0.25723\n",
      "[72]\tvalid_0's binary_logloss: 0.0492295\tvalid_0's f2: 0.256731\n",
      "[73]\tvalid_0's binary_logloss: 0.0735358\tvalid_0's f2: 0.253564\n",
      "[74]\tvalid_0's binary_logloss: 0.0358114\tvalid_0's f2: 0.258452\n",
      "[75]\tvalid_0's binary_logloss: 0.0401159\tvalid_0's f2: 0.255949\n",
      "[76]\tvalid_0's binary_logloss: 0.0365801\tvalid_0's f2: 0.256731\n",
      "[77]\tvalid_0's binary_logloss: 0.0517746\tvalid_0's f2: 0.254891\n",
      "[78]\tvalid_0's binary_logloss: 0.0474444\tvalid_0's f2: 0.255666\n",
      "[79]\tvalid_0's binary_logloss: 0.0457507\tvalid_0's f2: 0.255949\n",
      "[80]\tvalid_0's binary_logloss: 0.0600678\tvalid_0's f2: 0.254261\n",
      "[81]\tvalid_0's binary_logloss: 0.0475819\tvalid_0's f2: 0.256802\n",
      "[82]\tvalid_0's binary_logloss: 0.0851786\tvalid_0's f2: 0.252044\n",
      "[83]\tvalid_0's binary_logloss: 0.0503858\tvalid_0's f2: 0.256517\n",
      "[84]\tvalid_0's binary_logloss: 0.0408588\tvalid_0's f2: 0.257588\n",
      "[85]\tvalid_0's binary_logloss: 0.0778433\tvalid_0's f2: 0.25294\n",
      "[86]\tvalid_0's binary_logloss: 0.0403031\tvalid_0's f2: 0.257876\n",
      "[87]\tvalid_0's binary_logloss: 0.147416\tvalid_0's f2: 0.244063\n",
      "[88]\tvalid_0's binary_logloss: 0.0395682\tvalid_0's f2: 0.257517\n",
      "[89]\tvalid_0's binary_logloss: 0.0677862\tvalid_0's f2: 0.253633\n",
      "[90]\tvalid_0's binary_logloss: 0.0400094\tvalid_0's f2: 0.257588\n",
      "[91]\tvalid_0's binary_logloss: 0.0829877\tvalid_0's f2: 0.252649\n",
      "[92]\tvalid_0's binary_logloss: 0.0448733\tvalid_0's f2: 0.257016\n",
      "[93]\tvalid_0's binary_logloss: 0.044435\tvalid_0's f2: 0.257016\n",
      "[94]\tvalid_0's binary_logloss: 0.0694015\tvalid_0's f2: 0.253912\n",
      "[95]\tvalid_0's binary_logloss: 0.054753\tvalid_0's f2: 0.255808\n",
      "[96]\tvalid_0's binary_logloss: 0.0626285\tvalid_0's f2: 0.254961\n",
      "[97]\tvalid_0's binary_logloss: 0.107012\tvalid_0's f2: 0.248589\n",
      "[98]\tvalid_0's binary_logloss: 0.0411286\tvalid_0's f2: 0.256944\n",
      "[99]\tvalid_0's binary_logloss: 0.0402464\tvalid_0's f2: 0.257087\n",
      "[100]\tvalid_0's binary_logloss: 0.336121\tvalid_0's f2: 0.221716\n",
      "[101]\tvalid_0's binary_logloss: 0.0988\tvalid_0's f2: 0.24838\n",
      "[102]\tvalid_0's binary_logloss: 0.0555717\tvalid_0's f2: 0.255313\n",
      "[103]\tvalid_0's binary_logloss: 0.0450288\tvalid_0's f2: 0.256873\n",
      "[104]\tvalid_0's binary_logloss: 0.0467723\tvalid_0's f2: 0.256802\n",
      "[105]\tvalid_0's binary_logloss: 0.0439028\tvalid_0's f2: 0.25723\n",
      "[106]\tvalid_0's binary_logloss: 0.245161\tvalid_0's f2: 0.232646\n",
      "[107]\tvalid_0's binary_logloss: 0.0971788\tvalid_0's f2: 0.24723\n",
      "[108]\tvalid_0's binary_logloss: 0.041371\tvalid_0's f2: 0.255698\n",
      "[109]\tvalid_0's binary_logloss: 0.0404436\tvalid_0's f2: 0.255982\n",
      "[110]\tvalid_0's binary_logloss: 0.0398312\tvalid_0's f2: 0.256267\n",
      "[111]\tvalid_0's binary_logloss: 0.205831\tvalid_0's f2: 0.235656\n",
      "[112]\tvalid_0's binary_logloss: 0.079904\tvalid_0's f2: 0.248906\n",
      "[113]\tvalid_0's binary_logloss: 0.044948\tvalid_0's f2: 0.253059\n",
      "[114]\tvalid_0's binary_logloss: 0.0453304\tvalid_0's f2: 0.25452\n",
      "[115]\tvalid_0's binary_logloss: 0.0621112\tvalid_0's f2: 0.253513\n",
      "[116]\tvalid_0's binary_logloss: 0.469814\tvalid_0's f2: 0.209091\n",
      "[117]\tvalid_0's binary_logloss: 0.0469511\tvalid_0's f2: 0.254777\n",
      "[118]\tvalid_0's binary_logloss: 0.0400136\tvalid_0's f2: 0.256053\n",
      "[119]\tvalid_0's binary_logloss: 0.0481558\tvalid_0's f2: 0.254989\n",
      "[120]\tvalid_0's binary_logloss: 0.04284\tvalid_0's f2: 0.257159\n",
      "[121]\tvalid_0's binary_logloss: 0.0846498\tvalid_0's f2: 0.251359\n",
      "[122]\tvalid_0's binary_logloss: 0.0443505\tvalid_0's f2: 0.257016\n",
      "[123]\tvalid_0's binary_logloss: 0.0419746\tvalid_0's f2: 0.25723\n",
      "[124]\tvalid_0's binary_logloss: 0.0446211\tvalid_0's f2: 0.256873\n",
      "[125]\tvalid_0's binary_logloss: 0.0486315\tvalid_0's f2: 0.256446\n",
      "[126]\tvalid_0's binary_logloss: 0.0421834\tvalid_0's f2: 0.257373\n",
      "[127]\tvalid_0's binary_logloss: 0.129601\tvalid_0's f2: 0.245945\n",
      "[128]\tvalid_0's binary_logloss: 0.0526237\tvalid_0's f2: 0.255666\n",
      "[129]\tvalid_0's binary_logloss: 0.0409891\tvalid_0's f2: 0.257373\n",
      "[130]\tvalid_0's binary_logloss: 0.0386112\tvalid_0's f2: 0.257732\n",
      "[131]\tvalid_0's binary_logloss: 0.0475451\tvalid_0's f2: 0.256588\n",
      "[132]\tvalid_0's binary_logloss: 0.0418365\tvalid_0's f2: 0.25723\n",
      "[133]\tvalid_0's binary_logloss: 0.0513257\tvalid_0's f2: 0.255384\n",
      "[134]\tvalid_0's binary_logloss: 0.038558\tvalid_0's f2: 0.257732\n",
      "[135]\tvalid_0's binary_logloss: 0.107369\tvalid_0's f2: 0.248056\n",
      "[136]\tvalid_0's binary_logloss: 0.0383177\tvalid_0's f2: 0.25766\n",
      "[137]\tvalid_0's binary_logloss: 0.039014\tvalid_0's f2: 0.257588\n",
      "[138]\tvalid_0's binary_logloss: 0.0480794\tvalid_0's f2: 0.255878\n",
      "[139]\tvalid_0's binary_logloss: 0.0411799\tvalid_0's f2: 0.257302\n",
      "[140]\tvalid_0's binary_logloss: 0.0464957\tvalid_0's f2: 0.256517\n",
      "[141]\tvalid_0's binary_logloss: 0.0401\tvalid_0's f2: 0.256588\n",
      "[142]\tvalid_0's binary_logloss: 0.0383503\tvalid_0's f2: 0.257373\n",
      "[143]\tvalid_0's binary_logloss: 0.0392808\tvalid_0's f2: 0.257373\n",
      "[144]\tvalid_0's binary_logloss: 0.0399062\tvalid_0's f2: 0.25723\n",
      "[145]\tvalid_0's binary_logloss: 0.0382976\tvalid_0's f2: 0.25766\n",
      "[146]\tvalid_0's binary_logloss: 0.0391863\tvalid_0's f2: 0.25766\n",
      "[147]\tvalid_0's binary_logloss: 0.0387157\tvalid_0's f2: 0.257732\n",
      "[148]\tvalid_0's binary_logloss: 0.0464994\tvalid_0's f2: 0.256659\n",
      "[149]\tvalid_0's binary_logloss: 0.0397169\tvalid_0's f2: 0.257588\n",
      "[150]\tvalid_0's binary_logloss: 0.0972328\tvalid_0's f2: 0.249595\n",
      "[151]\tvalid_0's binary_logloss: 0.045255\tvalid_0's f2: 0.256446\n",
      "[152]\tvalid_0's binary_logloss: 0.040714\tvalid_0's f2: 0.257159\n",
      "[153]\tvalid_0's binary_logloss: 0.042072\tvalid_0's f2: 0.257087\n",
      "[154]\tvalid_0's binary_logloss: 0.0391538\tvalid_0's f2: 0.257517\n",
      "[155]\tvalid_0's binary_logloss: 0.0389098\tvalid_0's f2: 0.25766\n",
      "[156]\tvalid_0's binary_logloss: 0.0437254\tvalid_0's f2: 0.257016\n",
      "[157]\tvalid_0's binary_logloss: 0.053396\tvalid_0's f2: 0.255737\n",
      "[158]\tvalid_0's binary_logloss: 0.0436732\tvalid_0's f2: 0.257159\n",
      "[159]\tvalid_0's binary_logloss: 0.0425795\tvalid_0's f2: 0.25723\n",
      "[160]\tvalid_0's binary_logloss: 0.0425022\tvalid_0's f2: 0.257302\n",
      "[161]\tvalid_0's binary_logloss: 0.0421594\tvalid_0's f2: 0.257087\n",
      "[162]\tvalid_0's binary_logloss: 0.0422918\tvalid_0's f2: 0.257302\n",
      "[163]\tvalid_0's binary_logloss: 0.0432207\tvalid_0's f2: 0.257016\n",
      "[164]\tvalid_0's binary_logloss: 0.0445943\tvalid_0's f2: 0.256944\n",
      "[165]\tvalid_0's binary_logloss: 0.0430508\tvalid_0's f2: 0.257159\n",
      "[166]\tvalid_0's binary_logloss: 0.0442134\tvalid_0's f2: 0.256944\n",
      "[167]\tvalid_0's binary_logloss: 0.0433813\tvalid_0's f2: 0.257087\n",
      "[168]\tvalid_0's binary_logloss: 0.0418981\tvalid_0's f2: 0.25723\n",
      "[169]\tvalid_0's binary_logloss: 0.0419256\tvalid_0's f2: 0.257159\n",
      "[170]\tvalid_0's binary_logloss: 0.0631305\tvalid_0's f2: 0.254121\n",
      "[171]\tvalid_0's binary_logloss: 0.0454322\tvalid_0's f2: 0.256731\n",
      "[172]\tvalid_0's binary_logloss: 0.0416264\tvalid_0's f2: 0.25723\n",
      "[173]\tvalid_0's binary_logloss: 0.0417073\tvalid_0's f2: 0.257159\n",
      "[174]\tvalid_0's binary_logloss: 0.04508\tvalid_0's f2: 0.258047\n",
      "[175]\tvalid_0's binary_logloss: 0.0412412\tvalid_0's f2: 0.258549\n",
      "[176]\tvalid_0's binary_logloss: 0.0599027\tvalid_0's f2: 0.254681\n",
      "[177]\tvalid_0's binary_logloss: 0.0470903\tvalid_0's f2: 0.256375\n",
      "[178]\tvalid_0's binary_logloss: 0.0443974\tvalid_0's f2: 0.256375\n",
      "[179]\tvalid_0's binary_logloss: 0.0433341\tvalid_0's f2: 0.256731\n",
      "[180]\tvalid_0's binary_logloss: 0.0428159\tvalid_0's f2: 0.257159\n",
      "[181]\tvalid_0's binary_logloss: 0.0695354\tvalid_0's f2: 0.253147\n",
      "[182]\tvalid_0's binary_logloss: 0.0454897\tvalid_0's f2: 0.256802\n",
      "[183]\tvalid_0's binary_logloss: 0.0443826\tvalid_0's f2: 0.257087\n",
      "[184]\tvalid_0's binary_logloss: 0.0442813\tvalid_0's f2: 0.257087\n",
      "[185]\tvalid_0's binary_logloss: 0.0554499\tvalid_0's f2: 0.255454\n",
      "[186]\tvalid_0's binary_logloss: 0.0466812\tvalid_0's f2: 0.256873\n",
      "[187]\tvalid_0's binary_logloss: 0.0454568\tvalid_0's f2: 0.257016\n",
      "[188]\tvalid_0's binary_logloss: 0.0452825\tvalid_0's f2: 0.256944\n",
      "[189]\tvalid_0's binary_logloss: 0.0540266\tvalid_0's f2: 0.255454\n",
      "[190]\tvalid_0's binary_logloss: 0.0479\tvalid_0's f2: 0.256517\n",
      "[191]\tvalid_0's binary_logloss: 0.0438341\tvalid_0's f2: 0.25723\n",
      "[192]\tvalid_0's binary_logloss: 0.043455\tvalid_0's f2: 0.257302\n",
      "[193]\tvalid_0's binary_logloss: 0.0445002\tvalid_0's f2: 0.256588\n",
      "[194]\tvalid_0's binary_logloss: 0.0429657\tvalid_0's f2: 0.257159\n",
      "[195]\tvalid_0's binary_logloss: 0.045677\tvalid_0's f2: 0.256731\n",
      "[196]\tvalid_0's binary_logloss: 0.0458603\tvalid_0's f2: 0.256304\n",
      "[197]\tvalid_0's binary_logloss: 0.0449985\tvalid_0's f2: 0.256446\n",
      "[198]\tvalid_0's binary_logloss: 0.0470976\tvalid_0's f2: 0.256162\n",
      "[199]\tvalid_0's binary_logloss: 0.0441172\tvalid_0's f2: 0.256659\n",
      "[200]\tvalid_0's binary_logloss: 0.0431032\tvalid_0's f2: 0.256944\n",
      "[201]\tvalid_0's binary_logloss: 0.0420648\tvalid_0's f2: 0.257159\n",
      "[202]\tvalid_0's binary_logloss: 0.0450822\tvalid_0's f2: 0.256304\n",
      "[203]\tvalid_0's binary_logloss: 0.0420197\tvalid_0's f2: 0.257087\n",
      "[204]\tvalid_0's binary_logloss: 0.0427862\tvalid_0's f2: 0.256802\n",
      "[205]\tvalid_0's binary_logloss: 0.0422501\tvalid_0's f2: 0.257016\n",
      "[206]\tvalid_0's binary_logloss: 0.0426108\tvalid_0's f2: 0.256873\n",
      "[207]\tvalid_0's binary_logloss: 0.0455658\tvalid_0's f2: 0.256517\n",
      "[208]\tvalid_0's binary_logloss: 0.0439462\tvalid_0's f2: 0.256731\n",
      "[209]\tvalid_0's binary_logloss: 0.0480097\tvalid_0's f2: 0.256091\n",
      "[210]\tvalid_0's binary_logloss: 0.0440246\tvalid_0's f2: 0.256588\n",
      "[211]\tvalid_0's binary_logloss: 0.0439746\tvalid_0's f2: 0.256659\n",
      "[212]\tvalid_0's binary_logloss: 0.0574707\tvalid_0's f2: 0.254821\n",
      "[213]\tvalid_0's binary_logloss: 0.046775\tvalid_0's f2: 0.256446\n",
      "[214]\tvalid_0's binary_logloss: 0.0454723\tvalid_0's f2: 0.256588\n",
      "[215]\tvalid_0's binary_logloss: 0.0508002\tvalid_0's f2: 0.255878\n",
      "[216]\tvalid_0's binary_logloss: 0.0468958\tvalid_0's f2: 0.256304\n",
      "[217]\tvalid_0's binary_logloss: 0.0444766\tvalid_0's f2: 0.256731\n",
      "[218]\tvalid_0's binary_logloss: 0.0455499\tvalid_0's f2: 0.256517\n",
      "[219]\tvalid_0's binary_logloss: 0.0449615\tvalid_0's f2: 0.256873\n",
      "[220]\tvalid_0's binary_logloss: 0.0427978\tvalid_0's f2: 0.257087\n",
      "[221]\tvalid_0's binary_logloss: 0.0410374\tvalid_0's f2: 0.257373\n",
      "[222]\tvalid_0's binary_logloss: 0.0409517\tvalid_0's f2: 0.257588\n",
      "[223]\tvalid_0's binary_logloss: 0.0407695\tvalid_0's f2: 0.257588\n",
      "[224]\tvalid_0's binary_logloss: 0.0399782\tvalid_0's f2: 0.257732\n",
      "[225]\tvalid_0's binary_logloss: 0.0433003\tvalid_0's f2: 0.257302\n",
      "[226]\tvalid_0's binary_logloss: 0.0421783\tvalid_0's f2: 0.257445\n",
      "[227]\tvalid_0's binary_logloss: 0.0394011\tvalid_0's f2: 0.257804\n",
      "[228]\tvalid_0's binary_logloss: 0.0388489\tvalid_0's f2: 0.256339\n",
      "[229]\tvalid_0's binary_logloss: 0.0388167\tvalid_0's f2: 0.256482\n",
      "[230]\tvalid_0's binary_logloss: 0.0387883\tvalid_0's f2: 0.256482\n",
      "[231]\tvalid_0's binary_logloss: 0.0379052\tvalid_0's f2: 0.25684\n",
      "[232]\tvalid_0's binary_logloss: 0.0378842\tvalid_0's f2: 0.25802\n",
      "[233]\tvalid_0's binary_logloss: 0.0387885\tvalid_0's f2: 0.257948\n",
      "[234]\tvalid_0's binary_logloss: 0.0395893\tvalid_0's f2: 0.257876\n",
      "[235]\tvalid_0's binary_logloss: 0.0397155\tvalid_0's f2: 0.257948\n",
      "[236]\tvalid_0's binary_logloss: 0.0407041\tvalid_0's f2: 0.257732\n",
      "[237]\tvalid_0's binary_logloss: 0.039556\tvalid_0's f2: 0.257948\n",
      "[238]\tvalid_0's binary_logloss: 0.0395637\tvalid_0's f2: 0.257948\n",
      "[239]\tvalid_0's binary_logloss: 0.0394531\tvalid_0's f2: 0.257876\n",
      "[240]\tvalid_0's binary_logloss: 0.0384659\tvalid_0's f2: 0.259414\n",
      "[241]\tvalid_0's binary_logloss: 0.0397398\tvalid_0's f2: 0.260591\n",
      "[242]\tvalid_0's binary_logloss: 0.0385237\tvalid_0's f2: 0.260736\n",
      "[243]\tvalid_0's binary_logloss: 0.0385093\tvalid_0's f2: 0.260664\n",
      "[244]\tvalid_0's binary_logloss: 0.0440856\tvalid_0's f2: 0.25965\n",
      "[245]\tvalid_0's binary_logloss: 0.0398447\tvalid_0's f2: 0.260228\n",
      "[246]\tvalid_0's binary_logloss: 0.0396385\tvalid_0's f2: 0.260228\n",
      "[247]\tvalid_0's binary_logloss: 0.0396809\tvalid_0's f2: 0.260228\n",
      "[248]\tvalid_0's binary_logloss: 0.0385435\tvalid_0's f2: 0.260373\n",
      "[249]\tvalid_0's binary_logloss: 0.0393903\tvalid_0's f2: 0.260228\n",
      "[250]\tvalid_0's binary_logloss: 0.040145\tvalid_0's f2: 0.260156\n",
      "[251]\tvalid_0's binary_logloss: 0.0382501\tvalid_0's f2: 0.260373\n",
      "[252]\tvalid_0's binary_logloss: 0.0591038\tvalid_0's f2: 0.257009\n",
      "[253]\tvalid_0's binary_logloss: 0.0405289\tvalid_0's f2: 0.260011\n",
      "[254]\tvalid_0's binary_logloss: 0.0384296\tvalid_0's f2: 0.260373\n",
      "[255]\tvalid_0's binary_logloss: 0.038272\tvalid_0's f2: 0.260373\n",
      "[256]\tvalid_0's binary_logloss: 0.0362655\tvalid_0's f2: 0.260591\n",
      "[257]\tvalid_0's binary_logloss: 0.0362809\tvalid_0's f2: 0.260664\n",
      "[258]\tvalid_0's binary_logloss: 0.0382876\tvalid_0's f2: 0.260446\n",
      "[259]\tvalid_0's binary_logloss: 0.0361363\tvalid_0's f2: 0.260809\n",
      "[260]\tvalid_0's binary_logloss: 0.0378027\tvalid_0's f2: 0.260373\n",
      "[261]\tvalid_0's binary_logloss: 0.0352542\tvalid_0's f2: 0.260882\n",
      "[262]\tvalid_0's binary_logloss: 0.0348192\tvalid_0's f2: 0.260955\n",
      "[263]\tvalid_0's binary_logloss: 0.034586\tvalid_0's f2: 0.261027\n",
      "[264]\tvalid_0's binary_logloss: 0.0347834\tvalid_0's f2: 0.2611\n",
      "[265]\tvalid_0's binary_logloss: 0.0344022\tvalid_0's f2: 0.261246\n",
      "[266]\tvalid_0's binary_logloss: 0.0344014\tvalid_0's f2: 0.258524\n",
      "[267]\tvalid_0's binary_logloss: 0.0346434\tvalid_0's f2: 0.258308\n",
      "[268]\tvalid_0's binary_logloss: 0.0346254\tvalid_0's f2: 0.256911\n",
      "[269]\tvalid_0's binary_logloss: 0.0345744\tvalid_0's f2: 0.25684\n",
      "[270]\tvalid_0's binary_logloss: 0.034622\tvalid_0's f2: 0.25684\n",
      "[271]\tvalid_0's binary_logloss: 0.0345166\tvalid_0's f2: 0.256768\n",
      "[272]\tvalid_0's binary_logloss: 0.0343608\tvalid_0's f2: 0.256696\n",
      "[273]\tvalid_0's binary_logloss: 0.0343303\tvalid_0's f2: 0.257948\n",
      "[274]\tvalid_0's binary_logloss: 0.0366918\tvalid_0's f2: 0.257588\n",
      "[275]\tvalid_0's binary_logloss: 0.0363386\tvalid_0's f2: 0.257732\n",
      "[276]\tvalid_0's binary_logloss: 0.036083\tvalid_0's f2: 0.257876\n",
      "[277]\tvalid_0's binary_logloss: 0.0360907\tvalid_0's f2: 0.260373\n",
      "[278]\tvalid_0's binary_logloss: 0.0356577\tvalid_0's f2: 0.260446\n",
      "[279]\tvalid_0's binary_logloss: 0.0373493\tvalid_0's f2: 0.261402\n",
      "[280]\tvalid_0's binary_logloss: 0.0368155\tvalid_0's f2: 0.258909\n",
      "[281]\tvalid_0's binary_logloss: 0.0374172\tvalid_0's f2: 0.258621\n",
      "[282]\tvalid_0's binary_logloss: 0.0365299\tvalid_0's f2: 0.258981\n",
      "[283]\tvalid_0's binary_logloss: 0.0359843\tvalid_0's f2: 0.259053\n",
      "[284]\tvalid_0's binary_logloss: 0.0348355\tvalid_0's f2: 0.259197\n",
      "[285]\tvalid_0's binary_logloss: 0.0347191\tvalid_0's f2: 0.259197\n",
      "[286]\tvalid_0's binary_logloss: 0.0345381\tvalid_0's f2: 0.25927\n",
      "[287]\tvalid_0's binary_logloss: 0.0341455\tvalid_0's f2: 0.260664\n",
      "[288]\tvalid_0's binary_logloss: 0.0347639\tvalid_0's f2: 0.260591\n",
      "[289]\tvalid_0's binary_logloss: 0.0347623\tvalid_0's f2: 0.25927\n",
      "[290]\tvalid_0's binary_logloss: 0.0353057\tvalid_0's f2: 0.259197\n",
      "[291]\tvalid_0's binary_logloss: 0.0361355\tvalid_0's f2: 0.260373\n",
      "[292]\tvalid_0's binary_logloss: 0.0355582\tvalid_0's f2: 0.260446\n",
      "[293]\tvalid_0's binary_logloss: 0.0347484\tvalid_0's f2: 0.260591\n",
      "[294]\tvalid_0's binary_logloss: 0.0347234\tvalid_0's f2: 0.260664\n",
      "[295]\tvalid_0's binary_logloss: 0.0339442\tvalid_0's f2: 0.260809\n",
      "[296]\tvalid_0's binary_logloss: 0.0339417\tvalid_0's f2: 0.260809\n",
      "[297]\tvalid_0's binary_logloss: 0.0344856\tvalid_0's f2: 0.259414\n",
      "[298]\tvalid_0's binary_logloss: 0.0344875\tvalid_0's f2: 0.259414\n",
      "[299]\tvalid_0's binary_logloss: 0.0344253\tvalid_0's f2: 0.259487\n",
      "[300]\tvalid_0's binary_logloss: 0.0343299\tvalid_0's f2: 0.259414\n",
      "[301]\tvalid_0's binary_logloss: 0.0344952\tvalid_0's f2: 0.259487\n",
      "[302]\tvalid_0's binary_logloss: 0.0339442\tvalid_0's f2: 0.259559\n",
      "[303]\tvalid_0's binary_logloss: 0.0362532\tvalid_0's f2: 0.257876\n",
      "[304]\tvalid_0's binary_logloss: 0.0338962\tvalid_0's f2: 0.259414\n",
      "[305]\tvalid_0's binary_logloss: 0.0338098\tvalid_0's f2: 0.259487\n",
      "[306]\tvalid_0's binary_logloss: 0.0336553\tvalid_0's f2: 0.258092\n",
      "[307]\tvalid_0's binary_logloss: 0.0334545\tvalid_0's f2: 0.258092\n",
      "[308]\tvalid_0's binary_logloss: 0.03385\tvalid_0's f2: 0.258092\n",
      "[309]\tvalid_0's binary_logloss: 0.0337885\tvalid_0's f2: 0.258092\n",
      "[310]\tvalid_0's binary_logloss: 0.0337675\tvalid_0's f2: 0.256768\n",
      "[311]\tvalid_0's binary_logloss: 0.0336604\tvalid_0's f2: 0.256625\n",
      "[312]\tvalid_0's binary_logloss: 0.033647\tvalid_0's f2: 0.257732\n",
      "[313]\tvalid_0's binary_logloss: 0.0336733\tvalid_0's f2: 0.257732\n",
      "[314]\tvalid_0's binary_logloss: 0.0333827\tvalid_0's f2: 0.257732\n",
      "[315]\tvalid_0's binary_logloss: 0.0328242\tvalid_0's f2: 0.256482\n",
      "[316]\tvalid_0's binary_logloss: 0.03934\tvalid_0's f2: 0.253955\n",
      "[317]\tvalid_0's binary_logloss: 0.0353257\tvalid_0's f2: 0.25584\n",
      "[318]\tvalid_0's binary_logloss: 0.0351002\tvalid_0's f2: 0.25723\n",
      "[319]\tvalid_0's binary_logloss: 0.0353351\tvalid_0's f2: 0.257302\n",
      "[320]\tvalid_0's binary_logloss: 0.0347824\tvalid_0's f2: 0.257373\n",
      "[321]\tvalid_0's binary_logloss: 0.0334384\tvalid_0's f2: 0.256339\n",
      "[322]\tvalid_0's binary_logloss: 0.0328927\tvalid_0's f2: 0.256482\n",
      "[323]\tvalid_0's binary_logloss: 0.0329133\tvalid_0's f2: 0.256553\n",
      "[324]\tvalid_0's binary_logloss: 0.0329322\tvalid_0's f2: 0.25523\n",
      "[325]\tvalid_0's binary_logloss: 0.0329304\tvalid_0's f2: 0.255159\n",
      "[326]\tvalid_0's binary_logloss: 0.0334657\tvalid_0's f2: 0.253835\n",
      "[327]\tvalid_0's binary_logloss: 0.0332772\tvalid_0's f2: 0.25523\n",
      "[328]\tvalid_0's binary_logloss: 0.0329094\tvalid_0's f2: 0.255301\n",
      "[329]\tvalid_0's binary_logloss: 0.0328963\tvalid_0's f2: 0.255301\n",
      "[330]\tvalid_0's binary_logloss: 0.0328841\tvalid_0's f2: 0.255373\n",
      "[331]\tvalid_0's binary_logloss: 0.0328807\tvalid_0's f2: 0.255373\n",
      "[332]\tvalid_0's binary_logloss: 0.0341385\tvalid_0's f2: 0.257876\n",
      "[333]\tvalid_0's binary_logloss: 0.0335467\tvalid_0's f2: 0.259125\n",
      "[334]\tvalid_0's binary_logloss: 0.0328928\tvalid_0's f2: 0.25927\n",
      "[335]\tvalid_0's binary_logloss: 0.0328939\tvalid_0's f2: 0.25927\n",
      "[336]\tvalid_0's binary_logloss: 0.0328896\tvalid_0's f2: 0.257876\n",
      "[337]\tvalid_0's binary_logloss: 0.0328715\tvalid_0's f2: 0.255301\n",
      "[338]\tvalid_0's binary_logloss: 0.0323228\tvalid_0's f2: 0.255373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(n_estimators=1000, objective=&#x27;binary&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(n_estimators=1000, objective=&#x27;binary&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(n_estimators=1000, objective='binary')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=eval_set,\n",
    "    early_stopping_rounds=300,\n",
    "    eval_metric=lgb_f2_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7c50614-c034-490e-a41f-8159ffa260f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"data/X_test.csv\", index_col=0) \n",
    "y_test = pd.read_csv(\"data/y_test.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4de3d8fb-6d98-404c-aa97-d459167813fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44de599a-5a3a-4f23-89cb-7496f92bb998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2807051159225905"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, test_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "6109a054-d2f4-4382-aeb4-b21bab5b9dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9875492473054754, 0.25049871758335707, 0.5422578655151141)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_pred), recall_score(y_test, test_pred), precision_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64dae023-7160-4014-bdb1-e0ca3372a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df = pd.DataFrame()\n",
    "importances_df['feature'] = X_train.columns\n",
    "importances_df['gain'] = clf.booster_.feature_importance(importance_type='gain')\n",
    "importances_df['split'] = clf.booster_.feature_importance(importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97e31a0b-2956-4e37-ace5-24b414bbdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df['gain_log'] = np.log1p(importances_df['gain'])\n",
    "importances_df['split_log'] = np.log1p(importances_df['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ea4bde9b-fef4-4b22-a4a9-54841b2bfe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 8))\n",
    "sns.barplot(x='split_log', y='feature', data=importances_df.sort_values('split_log', ascending=False).head(20))\n",
    "\n",
    "# save the plot as a PNG file\n",
    "plt.savefig('feature_importance_split_lgbm_oob_top20.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c9d34a9-307d-4193-92b9-ece6fe0607bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "      <th>gain_log</th>\n",
       "      <th>split_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>channelGrouping</td>\n",
       "      <td>1,122.71</td>\n",
       "      <td>7</td>\n",
       "      <td>7.02</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visitNumber</td>\n",
       "      <td>15,551.77</td>\n",
       "      <td>95</td>\n",
       "      <td>9.65</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>totals_bounces</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totals_hits</td>\n",
       "      <td>6,491.16</td>\n",
       "      <td>127</td>\n",
       "      <td>8.78</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>totals_newVisits</td>\n",
       "      <td>19.13</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>geoNetwork_subContinent_device_deviceCategory</td>\n",
       "      <td>190.93</td>\n",
       "      <td>4</td>\n",
       "      <td>5.26</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>geoNetwork_subContinent_device_operatingSystem</td>\n",
       "      <td>116.29</td>\n",
       "      <td>4</td>\n",
       "      <td>4.76</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>geoNetwork_subContinent_trafficSource_source</td>\n",
       "      <td>253.25</td>\n",
       "      <td>6</td>\n",
       "      <td>5.54</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>content_source</td>\n",
       "      <td>26.57</td>\n",
       "      <td>2</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>medium_source</td>\n",
       "      <td>852.49</td>\n",
       "      <td>32</td>\n",
       "      <td>6.75</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           feature                 gain  \\\n",
       "0                                  channelGrouping             1,122.71   \n",
       "1                                      visitNumber            15,551.77   \n",
       "2                                   totals_bounces                 0.00   \n",
       "3                                      totals_hits             6,491.16   \n",
       "4                                 totals_newVisits                19.13   \n",
       "..                                             ...                  ...   \n",
       "64   geoNetwork_subContinent_device_deviceCategory               190.93   \n",
       "65  geoNetwork_subContinent_device_operatingSystem               116.29   \n",
       "66    geoNetwork_subContinent_trafficSource_source               253.25   \n",
       "67                                  content_source                26.57   \n",
       "68                                   medium_source               852.49   \n",
       "\n",
       "    split             gain_log            split_log  \n",
       "0       7                 7.02                 2.08  \n",
       "1      95                 9.65                 4.56  \n",
       "2       0                 0.00                 0.00  \n",
       "3     127                 8.78                 4.85  \n",
       "4       1                 3.00                 0.69  \n",
       "..    ...                  ...                  ...  \n",
       "64      4                 5.26                 1.61  \n",
       "65      4                 4.76                 1.61  \n",
       "66      6                 5.54                 1.95  \n",
       "67      2                 3.32                 1.10  \n",
       "68     32                 6.75                 3.50  \n",
       "\n",
       "[69 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "648eafcf-1cb0-459b-801a-15c005a4b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "693c477c-245e-447f-ac32-bc889dcfc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=11212184)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        train_x, test_x = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        train_y, test_y = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            eval_set=[(test_x, test_y)],\n",
    "            eval_metric=lgb_f2_score,\n",
    "            early_stopping_rounds=100,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, 'f2') \n",
    "            ],  # Add a pruning callback\n",
    "        )\n",
    "        preds = model.predict(test_x)\n",
    "        cv_scores[idx] = fbeta_score(test_y, preds,beta=2)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b215c5ba-bfe6-43f7-b4f1-2a94e17bb638",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:14:01,154]\u001b[0m A new study created in memory with name: LGBM Classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.353976608109104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.353976608109104\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.353976608109104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.353976608109104\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.353976608109104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.353976608109104\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.353976608109104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.353976608109104\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:19:25,397]\u001b[0m Trial 0 finished with value: 0.206034986694223 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2800427454907056, 'num_leaves': 2680, 'max_depth': 3, 'min_data_in_leaf': 800, 'lambda_l1': 20, 'lambda_l2': 40, 'min_gain_to_split': 9.353976608109104, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 0 with value: 0.206034986694223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.984761520757047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.984761520757047\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.984761520757047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.984761520757047\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.984761520757047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.984761520757047\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.984761520757047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.984761520757047\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.984761520757047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.984761520757047\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:22:29,929]\u001b[0m Trial 1 finished with value: 0.13799773027517787 and parameters: {'n_estimators': 10000, 'learning_rate': 0.23023002443887028, 'num_leaves': 540, 'max_depth': 12, 'min_data_in_leaf': 4200, 'lambda_l1': 95, 'lambda_l2': 70, 'min_gain_to_split': 7.984761520757047, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 0.206034986694223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.792975339860934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.792975339860934\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.792975339860934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.792975339860934\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.792975339860934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.792975339860934\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.792975339860934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.792975339860934\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.792975339860934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.792975339860934\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:26:48,689]\u001b[0m Trial 2 finished with value: 0.12939093059747422 and parameters: {'n_estimators': 10000, 'learning_rate': 0.26747785325714685, 'num_leaves': 660, 'max_depth': 7, 'min_data_in_leaf': 8700, 'lambda_l1': 80, 'lambda_l2': 55, 'min_gain_to_split': 10.792975339860934, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 0 with value: 0.206034986694223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.435762279507202, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435762279507202\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.435762279507202, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435762279507202\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.435762279507202, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435762279507202\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.435762279507202, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435762279507202\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.435762279507202, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435762279507202\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:34:01,611]\u001b[0m Trial 3 finished with value: 0.12632866050507677 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10138363364546689, 'num_leaves': 1500, 'max_depth': 7, 'min_data_in_leaf': 8000, 'lambda_l1': 80, 'lambda_l2': 65, 'min_gain_to_split': 5.435762279507202, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 0 with value: 0.206034986694223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.851642596346377, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.851642596346377\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.851642596346377, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.851642596346377\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.851642596346377, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.851642596346377\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.851642596346377, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.851642596346377\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.851642596346377, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.851642596346377\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:37:47,868]\u001b[0m Trial 4 finished with value: 0.20243543495445407 and parameters: {'n_estimators': 10000, 'learning_rate': 0.14679183041851998, 'num_leaves': 1260, 'max_depth': 9, 'min_data_in_leaf': 1100, 'lambda_l1': 60, 'lambda_l2': 5, 'min_gain_to_split': 11.851642596346377, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 0.206034986694223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.188419808437841, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.188419808437841\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:37:58,733]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:38:08,573]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:38:16,646]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:38:26,491]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:38:32,478]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:38:40,976]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.805565713370795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.805565713370795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.805565713370795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.805565713370795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.805565713370795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.805565713370795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.805565713370795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.805565713370795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:40:40,198]\u001b[0m Trial 11 finished with value: 0.40674110677241454 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1678067142404052, 'num_leaves': 2940, 'max_depth': 5, 'min_data_in_leaf': 400, 'lambda_l1': 20, 'lambda_l2': 0, 'min_gain_to_split': 14.805565713370795, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 11 with value: 0.40674110677241454.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.505670821678358, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.505670821678358\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:40:46,539]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:40:53,695]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:41:03,639]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:41:08,765]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:41:16,189]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:41:24,190]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.284168802081647, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.284168802081647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.284168802081647, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.284168802081647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.284168802081647, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.284168802081647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.284168802081647, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.284168802081647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:43:27,793]\u001b[0m Trial 18 finished with value: 0.3903751668412085 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2963316993184939, 'num_leaves': 2620, 'max_depth': 3, 'min_data_in_leaf': 2700, 'lambda_l1': 35, 'lambda_l2': 0, 'min_gain_to_split': 13.284168802081647, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 11 with value: 0.40674110677241454.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.457782188844181, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.457782188844181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.457782188844181, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.457782188844181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.457782188844181, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.457782188844181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.457782188844181, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.457782188844181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.457782188844181, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.457782188844181\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:45:29,461]\u001b[0m Trial 19 finished with value: 0.3984662535911818 and parameters: {'n_estimators': 10000, 'learning_rate': 0.15912434121295513, 'num_leaves': 1120, 'max_depth': 6, 'min_data_in_leaf': 2700, 'lambda_l1': 40, 'lambda_l2': 0, 'min_gain_to_split': 13.457782188844181, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 11 with value: 0.40674110677241454.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.815649269616696, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.815649269616696\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:45:34,092]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:45:38,762]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.51917936166962, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.51917936166962\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.51917936166962, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.51917936166962\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.51917936166962, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.51917936166962\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.51917936166962, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.51917936166962\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:47:39,905]\u001b[0m Trial 22 finished with value: 0.4556356529033529 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2106824320775506, 'num_leaves': 180, 'max_depth': 4, 'min_data_in_leaf': 5200, 'lambda_l1': 35, 'lambda_l2': 10, 'min_gain_to_split': 13.51917936166962, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 22 with value: 0.4556356529033529.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.435850296830619, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.435850296830619\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:47:44,705]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.706690769399401, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.706690769399401\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.706690769399401, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.706690769399401\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.706690769399401, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.706690769399401\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.706690769399401, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.706690769399401\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:50:00,217]\u001b[0m Trial 24 finished with value: 0.44685784252779304 and parameters: {'n_estimators': 10000, 'learning_rate': 0.20980476521984545, 'num_leaves': 20, 'max_depth': 8, 'min_data_in_leaf': 4900, 'lambda_l1': 10, 'lambda_l2': 10, 'min_gain_to_split': 13.706690769399401, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 22 with value: 0.4556356529033529.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.828166416367694, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.828166416367694\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:50:06,358]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 11:50:10,851]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.96985343663284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.96985343663284\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.96985343663284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.96985343663284\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.96985343663284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.96985343663284\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.96985343663284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.96985343663284\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:52:20,285]\u001b[0m Trial 27 finished with value: 0.46421596754032796 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2465988541197333, 'num_leaves': 340, 'max_depth': 8, 'min_data_in_leaf': 6900, 'lambda_l1': 20, 'lambda_l2': 20, 'min_gain_to_split': 14.96985343663284, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 27 with value: 0.46421596754032796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.425675692334995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.425675692334995\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.425675692334995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.425675692334995\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.425675692334995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.425675692334995\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.425675692334995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.425675692334995\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.425675692334995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.425675692334995\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:54:15,464]\u001b[0m Trial 28 finished with value: 0.4706916392195927 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2507581235788208, 'num_leaves': 300, 'max_depth': 8, 'min_data_in_leaf': 6800, 'lambda_l1': 0, 'lambda_l2': 20, 'min_gain_to_split': 12.425675692334995, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 28 with value: 0.4706916392195927.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.6951911493743, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.6951911493743\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:54:20,541]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.30899370894091, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.30899370894091\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.30899370894091, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.30899370894091\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.30899370894091, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.30899370894091\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.30899370894091, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.30899370894091\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:56:04,840]\u001b[0m Trial 30 finished with value: 0.46421596754032796 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2617174209103109, 'num_leaves': 340, 'max_depth': 11, 'min_data_in_leaf': 6800, 'lambda_l1': 20, 'lambda_l2': 20, 'min_gain_to_split': 12.30899370894091, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 28 with value: 0.4706916392195927.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.451879278915149, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.451879278915149\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.451879278915149, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.451879278915149\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.451879278915149, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.451879278915149\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.451879278915149, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.451879278915149\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.451879278915149, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.451879278915149\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:57:50,806]\u001b[0m Trial 31 finished with value: 0.45076103890199004 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2621905573066927, 'num_leaves': 380, 'max_depth': 12, 'min_data_in_leaf': 6700, 'lambda_l1': 20, 'lambda_l2': 20, 'min_gain_to_split': 12.451879278915149, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 28 with value: 0.4706916392195927.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.010237651719018, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.010237651719018\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6300\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:57:56,220]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.434800451725964, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.434800451725964\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.434800451725964, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.434800451725964\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.434800451725964, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.434800451725964\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.434800451725964, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.434800451725964\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 11:59:46,962]\u001b[0m Trial 33 finished with value: 0.5451123663790891 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2607643223046681, 'num_leaves': 240, 'max_depth': 11, 'min_data_in_leaf': 5600, 'lambda_l1': 15, 'lambda_l2': 20, 'min_gain_to_split': 12.434800451725964, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.285797539218567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.285797539218567\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.285797539218567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.285797539218567\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.285797539218567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.285797539218567\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.285797539218567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.285797539218567\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.285797539218567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.285797539218567\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:01:33,634]\u001b[0m Trial 34 finished with value: 0.5191579199683946 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2766188450565121, 'num_leaves': 460, 'max_depth': 11, 'min_data_in_leaf': 8100, 'lambda_l1': 10, 'lambda_l2': 30, 'min_gain_to_split': 9.285797539218567, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.869769264820919, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.869769264820919\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:01:37,805]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.057724805254159, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.057724805254159\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.057724805254159, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.057724805254159\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.057724805254159, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.057724805254159\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.057724805254159, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.057724805254159\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:03:25,798]\u001b[0m Trial 36 finished with value: 0.5001546390250582 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2834456409070413, 'num_leaves': 520, 'max_depth': 12, 'min_data_in_leaf': 7700, 'lambda_l1': 0, 'lambda_l2': 30, 'min_gain_to_split': 9.057724805254159, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.306675872644096, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.306675872644096\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.306675872644096, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.306675872644096\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.306675872644096, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.306675872644096\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.306675872644096, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.306675872644096\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.306675872644096, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.306675872644096\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:05:14,365]\u001b[0m Trial 37 finished with value: 0.5201254157646451 and parameters: {'n_estimators': 10000, 'learning_rate': 0.28428416311394455, 'num_leaves': 500, 'max_depth': 12, 'min_data_in_leaf': 9200, 'lambda_l1': 0, 'lambda_l2': 35, 'min_gain_to_split': 8.306675872644096, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.289638776499624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.289638776499624\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.289638776499624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.289638776499624\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.289638776499624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.289638776499624\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.289638776499624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.289638776499624\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.289638776499624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.289638776499624\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:07:01,132]\u001b[0m Trial 38 finished with value: 0.5201254157646451 and parameters: {'n_estimators': 10000, 'learning_rate': 0.299280756832675, 'num_leaves': 560, 'max_depth': 12, 'min_data_in_leaf': 9600, 'lambda_l1': 5, 'lambda_l2': 35, 'min_gain_to_split': 9.289638776499624, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.17547469663397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.17547469663397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.17547469663397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.17547469663397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.17547469663397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.17547469663397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.17547469663397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.17547469663397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.17547469663397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.17547469663397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:08:48,215]\u001b[0m Trial 39 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2965579097049783, 'num_leaves': 620, 'max_depth': 11, 'min_data_in_leaf': 9800, 'lambda_l1': 95, 'lambda_l2': 45, 'min_gain_to_split': 8.17547469663397, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.43178611786898, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.43178611786898\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:08:52,373]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:08:56,788]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:09:00,627]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:09:04,580]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:09:09,449]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.731838552558592, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.731838552558592\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.731838552558592, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.731838552558592\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.731838552558592, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.731838552558592\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.731838552558592, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.731838552558592\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:01,731]\u001b[0m Trial 45 finished with value: 0.5201254157646451 and parameters: {'n_estimators': 10000, 'learning_rate': 0.28856349534361686, 'num_leaves': 1380, 'max_depth': 10, 'min_data_in_leaf': 8800, 'lambda_l1': 5, 'lambda_l2': 35, 'min_gain_to_split': 8.731838552558592, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.945052326943984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.945052326943984\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.945052326943984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.945052326943984\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.945052326943984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.945052326943984\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.945052326943984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.945052326943984\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.945052326943984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.945052326943984\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:48,861]\u001b[0m Trial 46 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2996025333693379, 'num_leaves': 1700, 'max_depth': 10, 'min_data_in_leaf': 8800, 'lambda_l1': 5, 'lambda_l2': 50, 'min_gain_to_split': 6.945052326943984, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.519326465061216, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.519326465061216\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.519326465061216, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.519326465061216\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.519326465061216, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.519326465061216\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.519326465061216, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.519326465061216\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.519326465061216, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.519326465061216\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:14:32,091]\u001b[0m Trial 47 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2999854706578676, 'num_leaves': 1820, 'max_depth': 12, 'min_data_in_leaf': 9400, 'lambda_l1': 50, 'lambda_l2': 50, 'min_gain_to_split': 6.519326465061216, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.090657920296561, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.090657920296561\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:14:36,085]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:14:40,983]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:14:46,315]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.2873280939993546, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2873280939993546\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.2873280939993546, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2873280939993546\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.2873280939993546, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2873280939993546\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.2873280939993546, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2873280939993546\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:16:37,526]\u001b[0m Trial 51 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2970800392834333, 'num_leaves': 1720, 'max_depth': 12, 'min_data_in_leaf': 9500, 'lambda_l1': 15, 'lambda_l2': 45, 'min_gain_to_split': 6.2873280939993546, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.661627419465672, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.661627419465672\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.661627419465672, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.661627419465672\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.661627419465672, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.661627419465672\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.661627419465672, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.661627419465672\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.661627419465672, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.661627419465672\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:18:28,173]\u001b[0m Trial 52 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29941314606430064, 'num_leaves': 2160, 'max_depth': 11, 'min_data_in_leaf': 9500, 'lambda_l1': 15, 'lambda_l2': 55, 'min_gain_to_split': 5.661627419465672, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.435050810811211, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435050810811211\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:18:32,683]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534978117754769, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534978117754769\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534978117754769, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534978117754769\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534978117754769, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534978117754769\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534978117754769, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534978117754769\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:20:21,428]\u001b[0m Trial 54 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2906757534271671, 'num_leaves': 1740, 'max_depth': 10, 'min_data_in_leaf': 8500, 'lambda_l1': 30, 'lambda_l2': 55, 'min_gain_to_split': 5.534978117754769, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.412629437327959, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.412629437327959\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:20:25,831]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.878247043397171, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.878247043397171\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.878247043397171, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.878247043397171\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.878247043397171, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.878247043397171\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.878247043397171, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.878247043397171\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:22:14,538]\u001b[0m Trial 56 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29986971363378956, 'num_leaves': 1440, 'max_depth': 12, 'min_data_in_leaf': 9600, 'lambda_l1': 15, 'lambda_l2': 55, 'min_gain_to_split': 4.878247043397171, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.254355805290956, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.254355805290956\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:22:18,931]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:22:22,673]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:22:26,822]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:22:31,888]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.1594511948209405, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.1594511948209405\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.1594511948209405, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.1594511948209405\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.1594511948209405, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.1594511948209405\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.1594511948209405, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.1594511948209405\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:24:25,647]\u001b[0m Trial 61 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2925914628425756, 'num_leaves': 1800, 'max_depth': 11, 'min_data_in_leaf': 8500, 'lambda_l1': 15, 'lambda_l2': 55, 'min_gain_to_split': 6.1594511948209405, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.7160488167300025, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.7160488167300025\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:24:29,823]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.212720692282027, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.212720692282027\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.212720692282027, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.212720692282027\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.212720692282027, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.212720692282027\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.212720692282027, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.212720692282027\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:26:31,438]\u001b[0m Trial 63 finished with value: 0.5287997274354426 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29961493098726055, 'num_leaves': 1980, 'max_depth': 12, 'min_data_in_leaf': 9400, 'lambda_l1': 30, 'lambda_l2': 55, 'min_gain_to_split': 7.212720692282027, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.192739906247186, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.192739906247186\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.192739906247186, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.192739906247186\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.192739906247186, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.192739906247186\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.192739906247186, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.192739906247186\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.192739906247186, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.192739906247186\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:28:22,428]\u001b[0m Trial 64 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.299509057426242, 'num_leaves': 1920, 'max_depth': 12, 'min_data_in_leaf': 9400, 'lambda_l1': 55, 'lambda_l2': 45, 'min_gain_to_split': 7.192739906247186, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.737240554934376, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.737240554934376\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:28:27,225]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.585167753802156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.585167753802156\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.585167753802156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.585167753802156\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.585167753802156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.585167753802156\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.585167753802156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.585167753802156\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:30:35,525]\u001b[0m Trial 66 finished with value: 0.5272132579126269 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2680729001598051, 'num_leaves': 1600, 'max_depth': 12, 'min_data_in_leaf': 8900, 'lambda_l1': 20, 'lambda_l2': 40, 'min_gain_to_split': 7.585167753802156, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.872458114256592, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.872458114256592\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3800\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:30:41,153]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:30:47,730]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:30:52,352]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:31:00,246]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.553987830929779, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.553987830929779\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.553987830929779, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.553987830929779\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.553987830929779, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.553987830929779\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.553987830929779, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.553987830929779\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:33:13,628]\u001b[0m Trial 71 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29070375387244535, 'num_leaves': 1800, 'max_depth': 9, 'min_data_in_leaf': 8400, 'lambda_l1': 30, 'lambda_l2': 55, 'min_gain_to_split': 5.553987830929779, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.977265738898328, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.977265738898328\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.977265738898328, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.977265738898328\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.977265738898328, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.977265738898328\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.977265738898328, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.977265738898328\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.977265738898328, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.977265738898328\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:35:10,525]\u001b[0m Trial 72 finished with value: 0.5277717634553143 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2798731751755017, 'num_leaves': 1680, 'max_depth': 10, 'min_data_in_leaf': 9000, 'lambda_l1': 30, 'lambda_l2': 50, 'min_gain_to_split': 5.977265738898328, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.2063332502501485, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.2063332502501485\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.2063332502501485, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.2063332502501485\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.2063332502501485, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.2063332502501485\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.2063332502501485, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.2063332502501485\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.2063332502501485, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.2063332502501485\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:37:13,121]\u001b[0m Trial 73 finished with value: 0.5274534630239381 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29217078069674124, 'num_leaves': 1480, 'max_depth': 11, 'min_data_in_leaf': 8000, 'lambda_l1': 20, 'lambda_l2': 40, 'min_gain_to_split': 5.2063332502501485, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.349901523248331, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.349901523248331\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:37:17,991]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:37:24,217]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.722231219258867, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.722231219258867\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.722231219258867, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.722231219258867\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.722231219258867, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.722231219258867\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.722231219258867, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.722231219258867\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:39:15,057]\u001b[0m Trial 76 finished with value: 0.5554429830845798 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29949234220582965, 'num_leaves': 1140, 'max_depth': 12, 'min_data_in_leaf': 1000, 'lambda_l1': 45, 'lambda_l2': 50, 'min_gain_to_split': 5.722231219258867, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.711918484644375, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.711918484644375\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:39:19,104]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.025703597904879, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.025703597904879\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.025703597904879, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.025703597904879\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.025703597904879, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.025703597904879\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.025703597904879, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.025703597904879\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:41:05,911]\u001b[0m Trial 78 finished with value: 0.5554279072161915 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29934308619480454, 'num_leaves': 1100, 'max_depth': 12, 'min_data_in_leaf': 2200, 'lambda_l1': 60, 'lambda_l2': 45, 'min_gain_to_split': 6.025703597904879, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.602374209803397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.602374209803397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.602374209803397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.602374209803397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.602374209803397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.602374209803397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.602374209803397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.602374209803397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.602374209803397, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.602374209803397\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:43:24,716]\u001b[0m Trial 79 finished with value: 0.4792304120697718 and parameters: {'n_estimators': 10000, 'learning_rate': 0.28326092344640086, 'num_leaves': 1040, 'max_depth': 12, 'min_data_in_leaf': 700, 'lambda_l1': 60, 'lambda_l2': 45, 'min_gain_to_split': 8.602374209803397, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.1979378344101645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.1979378344101645\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.1979378344101645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.1979378344101645\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.1979378344101645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.1979378344101645\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.1979378344101645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.1979378344101645\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.1979378344101645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.1979378344101645\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:45:11,102]\u001b[0m Trial 80 finished with value: 0.5527620809951447 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2659737091892238, 'num_leaves': 1200, 'max_depth': 12, 'min_data_in_leaf': 1200, 'lambda_l1': 55, 'lambda_l2': 30, 'min_gain_to_split': 7.1979378344101645, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.012186554786735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.012186554786735\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.012186554786735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.012186554786735\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.012186554786735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.012186554786735\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.012186554786735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.012186554786735\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.012186554786735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.012186554786735\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:46:57,847]\u001b[0m Trial 81 finished with value: 0.5520426850445623 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29231986697734547, 'num_leaves': 760, 'max_depth': 12, 'min_data_in_leaf': 1400, 'lambda_l1': 55, 'lambda_l2': 25, 'min_gain_to_split': 7.012186554786735, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321568458594241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321568458594241\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321568458594241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321568458594241\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321568458594241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321568458594241\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321568458594241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321568458594241\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321568458594241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321568458594241\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:48:56,993]\u001b[0m Trial 82 finished with value: 0.5520426850445623 and parameters: {'n_estimators': 10000, 'learning_rate': 0.28441600395191613, 'num_leaves': 1180, 'max_depth': 12, 'min_data_in_leaf': 1400, 'lambda_l1': 55, 'lambda_l2': 25, 'min_gain_to_split': 7.321568458594241, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.337703782117573, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.337703782117573\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.337703782117573, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.337703782117573\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.337703782117573, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.337703782117573\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.337703782117573, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.337703782117573\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.337703782117573, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.337703782117573\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:51:07,174]\u001b[0m Trial 83 finished with value: 0.5527620809951447 and parameters: {'n_estimators': 10000, 'learning_rate': 0.26317735408249515, 'num_leaves': 1000, 'max_depth': 12, 'min_data_in_leaf': 1700, 'lambda_l1': 55, 'lambda_l2': 25, 'min_gain_to_split': 7.337703782117573, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.289140138542795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.289140138542795\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.289140138542795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.289140138542795\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.289140138542795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.289140138542795\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.289140138542795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.289140138542795\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.289140138542795, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.289140138542795\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:52:58,980]\u001b[0m Trial 84 finished with value: 0.5527620809951447 and parameters: {'n_estimators': 10000, 'learning_rate': 0.26396157158133143, 'num_leaves': 1020, 'max_depth': 12, 'min_data_in_leaf': 1600, 'lambda_l1': 55, 'lambda_l2': 25, 'min_gain_to_split': 8.289140138542795, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.398100290592787, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.398100290592787\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:53:04,486]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.555410430286981, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.555410430286981\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.555410430286981, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.555410430286981\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.555410430286981, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.555410430286981\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.555410430286981, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.555410430286981\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:55:12,173]\u001b[0m Trial 86 finished with value: 0.5527620809951447 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2642302183410722, 'num_leaves': 1200, 'max_depth': 12, 'min_data_in_leaf': 2000, 'lambda_l1': 60, 'lambda_l2': 25, 'min_gain_to_split': 8.555410430286981, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.382272597186649, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.382272597186649\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.382272597186649, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.382272597186649\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.382272597186649, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.382272597186649\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.382272597186649, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.382272597186649\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.382272597186649, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.382272597186649\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:57:15,638]\u001b[0m Trial 87 finished with value: 0.5527620809951447 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2634369048137022, 'num_leaves': 1140, 'max_depth': 12, 'min_data_in_leaf': 2100, 'lambda_l1': 60, 'lambda_l2': 25, 'min_gain_to_split': 8.382272597186649, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.371462725446547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.371462725446547\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.371462725446547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.371462725446547\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.371462725446547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.371462725446547\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.371462725446547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.371462725446547\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.371462725446547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.371462725446547\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:59:30,354]\u001b[0m Trial 88 finished with value: 0.5527620809951447 and parameters: {'n_estimators': 10000, 'learning_rate': 0.252548640688611, 'num_leaves': 1200, 'max_depth': 12, 'min_data_in_leaf': 2000, 'lambda_l1': 65, 'lambda_l2': 25, 'min_gain_to_split': 8.371462725446547, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.388588562607351, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.388588562607351\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.388588562607351, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.388588562607351\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.388588562607351, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.388588562607351\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.388588562607351, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.388588562607351\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.388588562607351, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.388588562607351\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 13:03:45,974]\u001b[0m Trial 89 finished with value: 0.4791331322073926 and parameters: {'n_estimators': 10000, 'learning_rate': 0.26661957756848204, 'num_leaves': 760, 'max_depth': 12, 'min_data_in_leaf': 2100, 'lambda_l1': 65, 'lambda_l2': 30, 'min_gain_to_split': 8.388588562607351, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 76 with value: 0.5554429830845798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.05982200689552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.05982200689552\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.05982200689552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.05982200689552\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.05982200689552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.05982200689552\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.05982200689552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.05982200689552\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-02-05 13:05:09,181]\u001b[0m Trial 90 failed with parameters: {'n_estimators': 10000, 'learning_rate': 0.2538492986865995, 'num_leaves': 1340, 'max_depth': 12, 'min_data_in_leaf': 1100, 'lambda_l1': 60, 'lambda_l2': 15, 'min_gain_to_split': 8.05982200689552, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.7} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3766/395478799.py\", line 2, in <lambda>\n",
      "    func = lambda trial: objective(trial, X_train, y_train.to_numpy().ravel()) ## does not like dataframes as ys\n",
      "  File \"/tmp/ipykernel_3766/1208543086.py\", line 28, in objective\n",
      "    model.fit(\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/engine.py\", line 299, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/basic.py\", line 3271, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/basic.py\", line 3272, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/basic.py\", line 3809, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 176, in __call__\n",
      "    return self.func(labels, preds)\n",
      "  File \"/tmp/ipykernel_3766/3865844390.py\", line 18, in lgb_f2_score\n",
      "    return 'f2', fbeta_score(y_true, y_pred, beta=2), True\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1277, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1567, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 487, in multilabel_confusion_matrix\n",
      "    present_labels = unique_labels(y_true, y_pred)\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/multiclass.py\", line 77, in unique_labels\n",
      "    ys_types = set(type_of_target(x) for x in ys)\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/multiclass.py\", line 77, in <genexpr>\n",
      "    ys_types = set(type_of_target(x) for x in ys)\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/multiclass.py\", line 335, in type_of_target\n",
      "    if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n",
      "  File \"<__array_function__ internals>\", line 180, in unique\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 272, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"/home/slawa/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 333, in _unique1d\n",
      "    ar.sort()\n",
      "KeyboardInterrupt\u001b[0m\n",
      "\u001b[33m[W 2023-02-05 13:05:09,190]\u001b[0m Trial 90 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3766/395478799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LGBM Classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## does not like dataframes as ys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3766/395478799.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LGBM Classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## does not like dataframes as ys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3766/1208543086.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, X, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         model.fit(\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   3269\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \"\"\"\n\u001b[0;32m-> 3271\u001b[0;31m         return [item for i in range(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   3272\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \"\"\"\n\u001b[1;32m   3271\u001b[0m         return [item for i in range(1, self.__num_dataset)\n\u001b[0;32m-> 3272\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m                 \u001b[0mfeval_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, preds, dataset)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0margc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0margc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3766/3865844390.py\u001b[0m in \u001b[0;36mlgb_f2_score\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     y_true = data.get_label()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# scikits f1 doesn't like probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'f2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \"\"\"\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1278\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m     \u001b[0msamplewise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     MCM = multilabel_confusion_matrix(\n\u001b[0m\u001b[1;32m   1568\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X_train, y_train.to_numpy().ravel()) ## does not like dataframes as ys / could it be that indexes fuck up performance?\n",
    "study.optimize(func, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7b4458fa-8e16-4b67-ad14-cb6157a9c41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3ee2da70-6c27-420e-becd-5b8cc0c76ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params1 = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c59447ed-5167-4df3-802f-22e301ec5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value1 = study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5cfbf584-994b-4b6e-849b-146d8e747075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 10000,\n",
       "  'learning_rate': 0.29949234220582965,\n",
       "  'num_leaves': 1140,\n",
       "  'max_depth': 12,\n",
       "  'min_data_in_leaf': 1000,\n",
       "  'lambda_l1': 45,\n",
       "  'lambda_l2': 50,\n",
       "  'min_gain_to_split': 5.722231219258867,\n",
       "  'bagging_fraction': 0.9,\n",
       "  'bagging_freq': 1,\n",
       "  'feature_fraction': 0.9},\n",
       " 0.5554429830845798)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params1,best_value1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ccd6d9-5dfa-4e9e-893f-5a117c510da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "231cf2bf-8014-4728-92fc-4f7b00ddc037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tn_estimators: 10000\n",
      "\t\tlearning_rate: 0.293209130675182\n",
      "\t\tnum_leaves: 2180\n",
      "\t\tmax_depth: 9\n",
      "\t\tmin_data_in_leaf: 3600\n",
      "\t\tlambda_l1: 0\n",
      "\t\tlambda_l2: 25\n",
      "\t\tmin_gain_to_split: 3.1647746391081357\n",
      "\t\tbagging_fraction: 0.4\n",
      "\t\tbagging_freq: 1\n",
      "\t\tfeature_fraction: 0.8\n"
     ]
    }
   ],
   "source": [
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e4163987-e1fa-4c81-97c7-8c04abf9544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "01cd5a65-6699-4770-9785-b573d3b8e97a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3766/3059678441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             )\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "best_value = study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e3b9b481-199f-42aa-b7cc-cce2888a5820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 10000,\n",
       "  'learning_rate': 0.293209130675182,\n",
       "  'num_leaves': 2180,\n",
       "  'max_depth': 9,\n",
       "  'min_data_in_leaf': 3600,\n",
       "  'lambda_l1': 0,\n",
       "  'lambda_l2': 25,\n",
       "  'min_gain_to_split': 3.1647746391081357,\n",
       "  'bagging_fraction': 0.4,\n",
       "  'bagging_freq': 1,\n",
       "  'feature_fraction': 0.8},\n",
       " 0.5502774609810496)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "833ad498-3329-4706-896f-4202214d057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5502774609810496"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af4cfa-81a6-4cf4-bf85-8164ba1ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trial 12 finished with value: 0.5502774609810496 and parameters: {'n_estimators': 10000, 'learning_rate': 0.293209130675182, 'num_leaves': 2180, 'max_depth': 9, 'min_data_in_leaf': 3600, 'lambda_l1': 0, 'lambda_l2': 25, 'min_gain_to_split': 3.1647746391081357, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 12 with value: 0.5502774609810496."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432deec-b5c0-454d-8f87-f85df3bb7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trial 33 finished with value: 0.5451123663790891 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2607643223046681, 'num_leaves': 240, 'max_depth': 11, 'min_data_in_leaf': 5600, 'lambda_l1': 15, 'lambda_l2': 20, 'min_gain_to_split': 12.434800451725964, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 33 with value: 0.5451123663790891."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "946590d1-6fc7-4c5f-af1e-45108dc2abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_params = {'n_estimators': 10000, 'learning_rate': 0.019940031689293848, 'num_leaves': 1020, 'max_depth': 9, 'min_data_in_leaf': 7800, 'lambda_l1': 45, 'lambda_l2': 65, 'min_gain_to_split': 1.2991787336282379, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf67eba-661e-485a-837b-9bc766c4f469",
   "metadata": {},
   "source": [
    "Trial 0 finished with value: 0.5703046075913167 and parameters: {'n_estimators': 10000, 'learning_rate': 0.019940031689293848, 'num_leaves': 1020, 'max_depth': 9, 'min_data_in_leaf': 7800, 'lambda_l1': 45, 'lambda_l2': 65, 'min_gain_to_split': 1.2991787336282379, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 0 with value: 0.5703046075913167.\n",
    "dart boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190bfa3-081c-4b0e-b9ef-c1fa9097fa6f",
   "metadata": {},
   "source": [
    "Try custom loss function with lgb for \"objective\" parameter.\n",
    "\n",
    "In the documentation of the LGBMClassifier:\n",
    "\n",
    "A custom objective function can be provided for the ``objective`` parameter.\n",
    "In this case, it should have the signature\n",
    "``objective(y_true, y_pred) -> grad, hess`` or\n",
    "``objective(y_true, y_pred, group) -> grad, hess``:\n",
    "\n",
    "    y_true : array-like of shape = [n_samples]\n",
    "        The target values.\n",
    "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
    "        The predicted values.\n",
    "        Predicted values are returned before any transformation,\n",
    "        e.g. they are raw margin instead of probability of positive class for binary task.\n",
    "    group : array-like\n",
    "        Group/query data.\n",
    "        Only used in the learning-to-rank task.\n",
    "        sum(group) = n_samples.\n",
    "        For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
    "        where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
    "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
    "        The value of the first order derivative (gradient) of the loss\n",
    "        with respect to the elements of y_pred for each sample point.\n",
    "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
    "        The value of the second order derivative (Hessian) of the loss\n",
    "        with respect to the elements of y_pred for each sample point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bf686be0-f073-4de2-81f0-5f956763a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    tp = np.sum(y_true*y_pred)\n",
    "    tn = np.sum((1-y_true)*(1-y_pred))\n",
    "    fp = np.sum((1-y_true)*y_pred)\n",
    "    fn = np.sum((y_true*(1-y_pred))\n",
    "\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2*p*r / (p+r)\n",
    "    loss = np.mean(f1)\n",
    "                \n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "10d015f6-1b34-4888-b24f-87677ca82ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    y_pred = special.expit(y_pred) # the preds array provided by LightGBM contains raw margin scores instead of probabilities. the preds array provided by LightGBM contains raw margin scores instead of probabilities. \n",
    "    #We have thus got to convert them to probabilities ourselves before evaluating the gradient and the Hessian by using a sigmoid transformation. \n",
    "    \n",
    "    tp = np.sum(y_true*y_pred)\n",
    "    tn = np.sum((1-y_true)*(1-y_pred))\n",
    "    fp = np.sum((1-y_true)*y_pred)\n",
    "    fn = np.sum(y_true*(1-y_pred))\n",
    "\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2*p*r / (p+r)\n",
    "\n",
    "    #loss = 1 - np.mean(f1)\n",
    "    return 1 - np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cf40c15f-c456-4097-add3-08146a39f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ae293-1557-441e-8b9e-35876d066a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8ef3684c-1097-4813-855e-7d1218fc0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_loss(y_true, y_pred):\n",
    "    \n",
    "    probs = 1. / (1. + np.exp(-y_pred))\n",
    "    precision = precision_score(y_true, np.round(probs))\n",
    "    recall = recall_score(y_true, np.round(probs))\n",
    "    numerator = 5 * precision * recall\n",
    "    denominator = 4 * precision + recall + 1e-5\n",
    "    grad = 5 * (precision * recall) / denominator\n",
    "    hess = 10 * (precision * recall) / (denominator ** 2)\n",
    "    return np.array([grad]), np.array([hess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c8d66f89-9d30-4c3f-b197-9ada3f2de360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_f2_loss(y_true, y_pred):\n",
    "    y_pred = 1. / (1. + np.exp(-y_pred))\n",
    "    \n",
    "    epsilon = 1e-15\n",
    "    \n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    y_pred = np.log(y_pred / (1 - y_pred))\n",
    "    \n",
    "    tp = np.sum(y_true * y_pred > 0)\n",
    "    fn = np.sum(y_true > y_pred)\n",
    "    fp = np.sum(y_pred > y_true)\n",
    "    \n",
    "    p = tp / (tp + fp + epsilon)\n",
    "    r = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    f2 = 5 * p * r / (4 * p + r + epsilon)\n",
    "    \n",
    "    grad = - (1 - f2) * (y_pred - y_true) / (y_pred * (1 - y_pred) + epsilon)\n",
    "    hess = np.zeros_like(y_pred)\n",
    "    \n",
    "    return grad, hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "82cd0c89-1c84-4fd6-937c-987ebf7982dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    \n",
    "    y_pred = 1 / (1 + np.exp(-y_pred))\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    tp = np.sum((y_true == 1) & (y_pred > 0.5))\n",
    "    fn = np.sum((y_true == 1) & (y_pred <= 0.5))\n",
    "    fp = np.sum((y_true == 0) & (y_pred > 0.5))\n",
    "    f2 = (5 * tp) / (5 * tp + 4 * fn + fp)\n",
    "    \n",
    "    grad = - (1 - f2) * (y_pred - y_true) / (y_pred * (1 - y_pred) + epsilon)\n",
    "    hess = (1 - f2) * ((y_pred - y_true) ** 2) / (y_pred * (1 - y_pred) + epsilon)\n",
    "    \n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e307d6ae-5543-4cae-b352-fd8cfad8b1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1ffcd8af-0e9b-4024-ad7d-6d30d72d9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e5cb868f-f5c1-4448-999c-76aeb2247b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.predict_proba(X_test, raw_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "167eafbc-236a-48f3-a6b4-64300f216ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.27990682]), array([0.23100807]))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2_loss(y_test.to_numpy().ravel(), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ca111067-d3a2-48f3-a015-fc0da02ddda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.72013915, -0.72013463, -0.72013463, ..., -0.7223465 ,\n",
       "        -0.72013148, -0.72013463]),\n",
       " array([4.71224711e-05, 4.26074958e-05, 4.26074958e-05, ...,\n",
       "        2.25447405e-03, 3.94511195e-05, 4.26074958e-05]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2_loss(y_test.to_numpy().ravel(), scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6970951-bc92-418a-ad2a-72d69dd6d9a4",
   "metadata": {},
   "source": [
    "In LightGBM (Gradient Boosting Tree library), the prediction for the positive class is usually represented by the second element of the prediction probability vector returned by the predict_proba method. The first element of this vector corresponds to the prediction for the negative class.\n",
    "\n",
    "For example, if the prediction vector is [0.1, 0.9], it means that the model predicts a probability of 0.9 for the positive class, and a probability of 0.1 for the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d83e15d6-8b3d-40aa-9466-182f9374e11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00035072, 0.0003285 , 0.0003285 , ..., 0.00263092, 0.0003285 ,\n",
       "       0.0003285 ])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c357ee5e-915a-48a7-b5e8-8fd684ef5840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679919</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304145</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755993</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35113</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656724</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322570</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371121</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859193</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518791</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218312</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270827 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        revenue_generated\n",
       "679919                  0\n",
       "304145                  0\n",
       "755993                  0\n",
       "35113                   0\n",
       "656724                  0\n",
       "...                   ...\n",
       "322570                  0\n",
       "371121                  0\n",
       "859193                  0\n",
       "518791                  0\n",
       "218312                  0\n",
       "\n",
       "[270827 rows x 1 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "affc74d3-9fb1-4a3d-bbcc-985cbec3a4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270827,)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy().ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c91d6cd0-5a54-4808-ab63-4abbbdc8c28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99649281e-01, 3.50719189e-04],\n",
       "       [9.99671498e-01, 3.28501858e-04],\n",
       "       [9.99671498e-01, 3.28501858e-04],\n",
       "       ...,\n",
       "       [9.97369082e-01, 2.63091755e-03],\n",
       "       [9.99671498e-01, 3.28501858e-04],\n",
       "       [9.99671498e-01, 3.28501858e-04]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0786940c-f545-434c-8094-9357b4b07c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597259990851743"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_loss(y_test.to_numpy().ravel(), test_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c70ad169-f7ac-4e23-a371-9736c39a5ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34269005847953216"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test.to_numpy().ravel(), np.round(test_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "39c4a7a4-0e88-417f-b6f8-240d3d0072c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "322d8e57-64fa-46a9-b5a7-4645e98d35cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eval_y.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbb3b9-730a-4540-9da9-3842de17f9e4",
   "metadata": {},
   "source": [
    "Creating a baseline score with out-of-the box logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "1e232c25-10e5-4a39-a5aa-9701d2096deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, eval_x, train_y, eval_y = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "63e47aa8-b7b7-46bd-99a0-a1247b3b9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "51e6f32e-d06d-491b-8dfa-df05d053d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = X_train.copy()\n",
    "X_test_pp = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "e5d2a3db-ef83-4b74-917f-38ad2cb12e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SimpleImputer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_train_pp.days_since_visit.to_numpy().reshape(-1,1)) # fit on train data to prevent leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "db07281f-4929-42fa-904f-4c6fc2e561fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp.days_since_visit = imp_mean.transform(X_train_pp.days_since_visit.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "7a925275-c041-4cae-b6f0-638fea6028ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pp.days_since_visit = imp_mean.transform(X_test_pp.days_since_visit.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6e2ed148-b212-4fef-b266-c02e0b65aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "de6e55e9-9140-476c-bfec-46e7965904b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_pp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f708f5f3-ae1b-4eb8-9d7e-0d3c1e4e9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(X_test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e6a0864c-4a47-47f6-b622-b8ef779b0269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21365624801876626"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, lr_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "b09eb9eb-9257-43f0-a150-3bfc6c419c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9856070480417388 \n",
      " recall:  0.1920775149615275 \n",
      " precision:  0.3880253310305124 \n",
      " f2:  0.21365624801876626\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', accuracy_score(y_test, lr_pred), '\\n',\n",
    "      'recall: ', recall_score(y_test, lr_pred), '\\n',\n",
    "      'precision: ', precision_score(y_test, lr_pred), '\\n', \n",
    "      'f2: ', fbeta_score(y_test, lr_pred, beta=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2f3804bd-8e4c-49b5-b4cb-63022673406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = lgb.LGBMClassifier(objective='binary', n_estimators=1000)\n",
    "\n",
    "#clf1 = lgb.LGBMClassifier(objective=f2_loss, n_estimators=1000)\n",
    "eval_set = [(eval_x, eval_y.to_numpy().ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "60b7d936-d2fc-426e-ab78-492d79065587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, eval_x, train_y, eval_y = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "clf1 = lgb.LGBMClassifier(**best_params1)\n",
    "\n",
    "#clf1 = lgb.LGBMClassifier(objective=f2_loss, n_estimators=1000)\n",
    "eval_set = [(eval_x, eval_y.to_numpy().ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7a1bd2fe-8871-4966-9bc2-1f518738ff08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.0492918\tvalid_0's f2: 0.567203\n",
      "[2]\tvalid_0's binary_logloss: 0.0421181\tvalid_0's f2: 0.567203\n",
      "[3]\tvalid_0's binary_logloss: 0.0387553\tvalid_0's f2: 0.254151\n",
      "[4]\tvalid_0's binary_logloss: 0.0364904\tvalid_0's f2: 0.229221\n",
      "[5]\tvalid_0's binary_logloss: 0.0346859\tvalid_0's f2: 0.142593\n",
      "[6]\tvalid_0's binary_logloss: 0.0334679\tvalid_0's f2: 0.124779\n",
      "[7]\tvalid_0's binary_logloss: 0.0324524\tvalid_0's f2: 0.130725\n",
      "[8]\tvalid_0's binary_logloss: 0.0318288\tvalid_0's f2: 0.154318\n",
      "[9]\tvalid_0's binary_logloss: 0.0311501\tvalid_0's f2: 0.142004\n",
      "[10]\tvalid_0's binary_logloss: 0.0308261\tvalid_0's f2: 0.146125\n",
      "[11]\tvalid_0's binary_logloss: 0.0305391\tvalid_0's f2: 0.153659\n",
      "[12]\tvalid_0's binary_logloss: 0.0303382\tvalid_0's f2: 0.147735\n",
      "[13]\tvalid_0's binary_logloss: 0.0301857\tvalid_0's f2: 0.158637\n",
      "[14]\tvalid_0's binary_logloss: 0.0299757\tvalid_0's f2: 0.164675\n",
      "[15]\tvalid_0's binary_logloss: 0.0297905\tvalid_0's f2: 0.154101\n",
      "[16]\tvalid_0's binary_logloss: 0.0297096\tvalid_0's f2: 0.161918\n",
      "[17]\tvalid_0's binary_logloss: 0.0296354\tvalid_0's f2: 0.167945\n",
      "[18]\tvalid_0's binary_logloss: 0.0295328\tvalid_0's f2: 0.178951\n",
      "[19]\tvalid_0's binary_logloss: 0.029464\tvalid_0's f2: 0.177154\n",
      "[20]\tvalid_0's binary_logloss: 0.0294257\tvalid_0's f2: 0.179936\n",
      "[21]\tvalid_0's binary_logloss: 0.0293978\tvalid_0's f2: 0.179383\n",
      "[22]\tvalid_0's binary_logloss: 0.0293751\tvalid_0's f2: 0.184703\n",
      "[23]\tvalid_0's binary_logloss: 0.029285\tvalid_0's f2: 0.187398\n",
      "[24]\tvalid_0's binary_logloss: 0.0292631\tvalid_0's f2: 0.18966\n",
      "[25]\tvalid_0's binary_logloss: 0.0292305\tvalid_0's f2: 0.192419\n",
      "[26]\tvalid_0's binary_logloss: 0.0292183\tvalid_0's f2: 0.192419\n",
      "[27]\tvalid_0's binary_logloss: 0.0291875\tvalid_0's f2: 0.191086\n",
      "[28]\tvalid_0's binary_logloss: 0.0291568\tvalid_0's f2: 0.192955\n",
      "[29]\tvalid_0's binary_logloss: 0.0291478\tvalid_0's f2: 0.193825\n",
      "[30]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[31]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[32]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[33]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[34]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[35]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[36]\tvalid_0's binary_logloss: 0.0291401\tvalid_0's f2: 0.195504\n",
      "[37]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[38]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[39]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[40]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[41]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[42]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[43]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[44]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[45]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[46]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[47]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[48]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[49]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[50]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[51]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[52]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[53]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[54]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[55]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[56]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[57]\tvalid_0's binary_logloss: 0.0291338\tvalid_0's f2: 0.198561\n",
      "[58]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[59]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[60]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[61]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[62]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[63]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[64]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[65]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[66]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[67]\tvalid_0's binary_logloss: 0.0291272\tvalid_0's f2: 0.199022\n",
      "[68]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[69]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[70]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[71]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[72]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[73]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[74]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[75]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[76]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[77]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[78]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[79]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[80]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[81]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[82]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[83]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[84]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[85]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[86]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[87]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[88]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[89]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[90]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[91]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[92]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[93]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[94]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[95]\tvalid_0's binary_logloss: 0.0291251\tvalid_0's f2: 0.198139\n",
      "[96]\tvalid_0's binary_logloss: 0.0291139\tvalid_0's f2: 0.199463\n",
      "[97]\tvalid_0's binary_logloss: 0.0291139\tvalid_0's f2: 0.199463\n",
      "[98]\tvalid_0's binary_logloss: 0.0291139\tvalid_0's f2: 0.199463\n",
      "[99]\tvalid_0's binary_logloss: 0.0291139\tvalid_0's f2: 0.199463\n",
      "[100]\tvalid_0's binary_logloss: 0.0291139\tvalid_0's f2: 0.199463\n",
      "[101]\tvalid_0's binary_logloss: 0.0291139\tvalid_0's f2: 0.199463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.9, bagging_freq=1, feature_fraction=0.9,\n",
       "               lambda_l1=45, lambda_l2=50, learning_rate=0.29949234220582965,\n",
       "               max_depth=12, min_data_in_leaf=1000,\n",
       "               min_gain_to_split=5.722231219258867, n_estimators=10000,\n",
       "               num_leaves=1140)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.9, bagging_freq=1, feature_fraction=0.9,\n",
       "               lambda_l1=45, lambda_l2=50, learning_rate=0.29949234220582965,\n",
       "               max_depth=12, min_data_in_leaf=1000,\n",
       "               min_gain_to_split=5.722231219258867, n_estimators=10000,\n",
       "               num_leaves=1140)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=1, feature_fraction=0.9,\n",
       "               lambda_l1=45, lambda_l2=50, learning_rate=0.29949234220582965,\n",
       "               max_depth=12, min_data_in_leaf=1000,\n",
       "               min_gain_to_split=5.722231219258867, n_estimators=10000,\n",
       "               num_leaves=1140)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(\n",
    "    train_x,\n",
    "    train_y.to_numpy().ravel(),\n",
    "    eval_set=eval_set,\n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric=lgb_f2_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "6589975b-c606-419d-97c9-875a33b9c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pred = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4e7ccd17-d835-4924-8d29-256c19ade0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_val = fbeta_score(y_test, clf_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "3f4574f5-ed41-469c-bce3-f30ac586a049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5688635770802539"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "c15e9779-5328-428d-b94b-c61c639b9bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457965232259903"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a80806e9-b0a0-4111-9c8a-7e969d67489a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2918804372072273"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "adebc168-1023-4914-8fdd-4111de64a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732633747743025"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "28fe8ea4-5125-4741-aff1-ddef109efebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(clf1, importance_type='split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a921056-ab42-4579-b822-ca0d6d3e78ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7a04ab8f-0f5c-457a-bd1a-661c3f5aabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances1_df = pd.DataFrame()\n",
    "importances1_df['feature'] = X_train.columns\n",
    "importances1_df['gain'] = clf1.booster_.feature_importance(importance_type='gain')\n",
    "importances1_df['split'] = clf1.booster_.feature_importance(importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1b6f9f47-87e1-4dfd-99ef-3b3edd6ce890",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances1_df['gain_log'] = np.log1p(importances1_df['gain'])\n",
    "importances1_df['split_log'] = np.log1p(importances1_df['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b7354656-399e-487b-adb7-84acfb8c39b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "sns.barplot(x='split', y='feature', data=importances1_df.sort_values('split', ascending=False).head(4));\n",
    "\n",
    "# save the plot as a PNG file\n",
    "plt.savefig('feature_importance_split_lgbm_opt_only4.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f6734e13-b68d-4db9-a1b0-7eb04a448e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "556c583d-1625-41dd-95ca-23224692289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blind_zero_pred(df):\n",
    "    return np.zeros(df.shape[0],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "89bb65c1-2aa2-4b69-869a-5b0b920b9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blind_ones_pred(df):\n",
    "    return np.ones(df.shape[0],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "7ebaeef8-0f8e-4aec-8b64-422083966e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, blind_zero_pred(X_test), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "3b3e9954-b1ff-4a53-ae72-fe971047db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012956610677665077"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, blind_ones_pred(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ab70e072-bc4e-4e9c-a0d0-345665e7fd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, blind_ones_pred(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "19da1639-7bf9-4bfd-baa2-cbdbfb92e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012956610677665077"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, blind_ones_pred(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d96b3345-a222-4681-963d-a4604d4e8eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061591010415533075"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, blind_ones_pred(X_test), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1ffd4-16ed-4d5f-8334-56583219cee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
